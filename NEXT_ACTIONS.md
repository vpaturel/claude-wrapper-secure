# üéØ Prochaines Actions - Documentation Claude API (60% ‚Üí 85%)

**Date** : 2025-11-05 15:00
**√âtat actuel** : 60% compl√©t√©
**Objectif** : 85% (Features + Limites + Mod√®les)

---

## üìä Sections Prioritaires

### 1. Features Avanc√©es (10% ‚Üí 50%) - Priorit√© HAUTE
**Impact** : +20% documentation totale
**Temps estim√©** : 2-3 heures

### 2. Limites et Quotas (0% ‚Üí 60%) - Priorit√© MOYENNE
**Impact** : +10% documentation totale
**Temps estim√©** : 1-2 heures

### 3. Mod√®les Disponibles (5% ‚Üí 70%) - Priorit√© MOYENNE
**Impact** : +5% documentation totale
**Temps estim√©** : 1 heure

---

## üöÄ ACTION 1 : Tool Calling (1h)

### Objectif
Capturer et documenter l'utilisation compl√®te des tools/function calling

### M√©thode
```bash
# 1. Lancer proxy capture
cd /home/tincenv/analyse-claude-ai
python3 proxy_capture_full.py > /tmp/proxy_tools.log 2>&1 &

# 2. Cr√©er requ√™te avec tool
cat > /tmp/test_tool.py <<'EOF'
import anthropic

client = anthropic.Anthropic()

response = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    tools=[{
        "name": "get_weather",
        "description": "Get weather for a location",
        "input_schema": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "City name"},
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
            },
            "required": ["location"]
        }
    }],
    messages=[{"role": "user", "content": "What's the weather in Paris?"}]
)

print(response.model_dump_json(indent=2))
EOF

# 3. Ex√©cuter avec proxy
HTTP_PROXY=http://localhost:8000 python3 /tmp/test_tool.py

# 4. Analyser capture
ls -lt captures/requests/ | head -5
```

### √Ä documenter
- [ ] Structure `tools` dans requ√™te
- [ ] Format `input_schema` (JSON Schema)
- [ ] R√©ponse `tool_use` du mod√®le
- [ ] Format `tool_result` pour r√©ponse
- [ ] Gestion multi-tools
- [ ] Erreurs tool calling

---

## üöÄ ACTION 2 : Image Upload (45 min)

### Objectif
Capturer requ√™te avec image base64

### M√©thode
```bash
# 1. Cr√©er image de test
echo "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==" > /tmp/test.b64

# 2. Test avec image
cat > /tmp/test_image.py <<'EOF'
import anthropic
import base64

client = anthropic.Anthropic()

with open("/tmp/test.b64") as f:
    image_data = f.read()

response = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=1024,
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "Describe this image"},
            {
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/png",
                    "data": image_data
                }
            }
        ]
    }]
)

print(response.model_dump_json(indent=2))
EOF

HTTP_PROXY=http://localhost:8000 python3 /tmp/test_image.py
```

### √Ä documenter
- [ ] Format `image` content type
- [ ] Structure `source` (base64)
- [ ] `media_type` support√©s (png, jpg, gif, webp)
- [ ] Taille max image
- [ ] Multi-images dans une requ√™te
- [ ] Erreurs image (trop grande, format invalide)

---

## üöÄ ACTION 3 : Rate Limits (30 min)

### Objectif
D√©clencher et capturer rate limiting

### M√©thode
```bash
# Lancer 100 requ√™tes rapides
for i in {1..100}; do
  HTTP_PROXY=http://localhost:8000 claude chat "test $i" &
  sleep 0.1
done

# Attendre completion
wait

# Analyser erreurs 429
grep -r "429" captures/errors/
```

### √Ä documenter
- [ ] Headers `x-ratelimit-*` dans r√©ponses
- [ ] Format erreur 429 (rate_limit_error)
- [ ] Message d'erreur exact
- [ ] Retry-After header
- [ ] Limites par plan (Max vs Pro)

---

## üöÄ ACTION 4 : Diff√©rents Mod√®les (30 min)

### Objectif
Tester tous les mod√®les disponibles via OAuth

### M√©thode
```bash
# Tester chaque mod√®le
for model in "claude-opus-4-20250514" "claude-sonnet-4-5-20250929" "claude-3-5-haiku-20241022" "claude-3-5-sonnet-20241022"; do
  echo "Testing $model..."
  HTTP_PROXY=http://localhost:8000 claude --model $model chat "Hello, what model are you?"
  sleep 2
done
```

### √Ä documenter
- [ ] Liste mod√®les disponibles OAuth
- [ ] Noms exacts (IDs)
- [ ] Context window par mod√®le
- [ ] Max tokens output par mod√®le
- [ ] Diff√©rences OAuth vs API Key
- [ ] Erreurs mod√®le non disponible

---

## üöÄ ACTION 5 : Prompt Caching (20 min)

### Objectif
Tester si prompt caching disponible avec OAuth

### M√©thode
```bash
cat > /tmp/test_cache.py <<'EOF'
import anthropic

client = anthropic.Anthropic()

# Large system prompt (should be cached)
large_prompt = "You are a helpful assistant. " * 1000

for i in range(3):
    response = client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=100,
        system=[{
            "type": "text",
            "text": large_prompt,
            "cache_control": {"type": "ephemeral"}
        }],
        messages=[{"role": "user", "content": f"Test {i}"}]
    )
    print(f"Request {i}: {response.usage}")
EOF

HTTP_PROXY=http://localhost:8000 python3 /tmp/test_cache.py
```

### √Ä documenter
- [ ] Disponible avec OAuth ? (oui/non)
- [ ] Headers prompt caching
- [ ] Structure `cache_control`
- [ ] Usage response avec cache hits
- [ ] Diff√©rences vs API Key

---

## üöÄ ACTION 6 : Long Context (30 min)

### Objectif
Tester limite context window

### M√©thode
```bash
# G√©n√©rer gros contexte (~50K tokens)
python3 -c "print('A' * 200000)" > /tmp/large_context.txt

cat > /tmp/test_context.py <<'EOF'
import anthropic

client = anthropic.Anthropic()

with open("/tmp/large_context.txt") as f:
    large_text = f.read()

response = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    max_tokens=100,
    messages=[{
        "role": "user",
        "content": f"Summarize: {large_text}"
    }]
)

print(response.model_dump_json(indent=2))
EOF

HTTP_PROXY=http://localhost:8000 python3 /tmp/test_context.py
```

### √Ä documenter
- [ ] Context window exact (200K tokens ?)
- [ ] Erreur si d√©passement (400 + message)
- [ ] Comptage tokens (approximatif vs exact)
- [ ] Performance (latence avec gros contexte)

---

## üöÄ ACTION 7 : Headers Complets (15 min)

### Objectif
Capturer tous les headers de r√©ponse

### M√©thode
```bash
# Analyser captures existantes
jq '.response_headers' captures/requests/*.json | sort -u

# Tester cas sp√©ciaux
HTTP_PROXY=http://localhost:8000 claude chat "Test headers"
```

### √Ä documenter
- [ ] `request-id` (UUID)
- [ ] `anthropic-organization-id` (si pr√©sent)
- [ ] `x-ratelimit-*` complets
- [ ] `content-type` (text/event-stream)
- [ ] Headers debug/versioning

---

## üìä Temps Estim√© Total : 4-5 heures

| Action | Temps | Impact |
|--------|-------|--------|
| Tool calling | 1h | +8% |
| Image upload | 45min | +5% |
| Rate limits | 30min | +3% |
| Mod√®les | 30min | +5% |
| Prompt caching | 20min | +2% |
| Long context | 30min | +2% |
| Headers | 15min | +2% |
| **TOTAL** | **4h30** | **+27%** |

**Progression finale estim√©e** : 60% + 27% = **87%**

---

## üéØ R√©sultat Attendu

### Documentation compl√®te de :
1. ‚úÖ Authentification OAuth (70%)
2. ‚úÖ Streaming SSE (95%)
3. ‚úÖ Erreurs HTTP (70%)
4. üÜï **Features avanc√©es (50%)** ‚Üê Nouveau
5. üÜï **Limites/Quotas (60%)** ‚Üê Nouveau
6. üÜï **Mod√®les (70%)** ‚Üê Nouveau
7. ‚è≥ API Messages (35% ‚Üí 50%)

**Total final** : **85-87%**

---

## üìù Template Capture

Pour chaque action, cr√©er fichier markdown :

```markdown
# Feature: [NOM]

## Requ√™te

\`\`\`json
{requ√™te captur√©e}
\`\`\`

## R√©ponse

\`\`\`json
{r√©ponse captur√©e}
\`\`\`

## Structure

- **Champ X** : Description
- **Champ Y** : Description

## Erreurs Possibles

- `error_type_1` : Description
- `error_type_2` : Description

## Exemples

\`\`\`python
# Exemple d'utilisation
\`\`\`

## Diff√©rences OAuth vs API Key

- OAuth : ...
- API Key : ...
```

---

## üöÄ Quick Start

```bash
# 1. Lancer proxy
cd /home/tincenv/analyse-claude-ai
python3 proxy_capture_full.py > /tmp/proxy_features.log 2>&1 &

# 2. Choisir une action
# Voir d√©tails ci-dessus

# 3. Analyser captures
ls -lt captures/requests/ | head -10
jq '.' captures/requests/[LATEST].json

# 4. Documenter dans markdown
vim FEATURE_[NOM].md
```

---

**Pr√™t √† commencer ?**

Choisis une action (1-7) ou d√©marre par la plus simple (Action 2 : Images).
