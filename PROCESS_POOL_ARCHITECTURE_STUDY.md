# ğŸ”„ Process Pool Architecture - Ã‰tude ComplÃ¨te

**Date**: 2025-11-07
**Version**: v32 (Ã©tude prÃ©paratoire)
**Status**: ğŸ“š Document d'Ã©tude

---

## ğŸ¯ Objectif

Comprendre l'architecture du **process pool** pour implÃ©menter un vrai keep-alive multi-requÃªtes.

---

## ğŸ“Š Comparaison des Architectures

### Architecture Actuelle (v31) - Single-Request Keep-Alive

```
Client Request â†’ FastAPI
                   â†“
            Spawn Process
                   â†“
            Send Message
                   â†“
            Stream Response
                   â†“
            Destroy Process âŒ
                   â†“
            Return to Client
```

**CaractÃ©ristiques**:
- âœ… Process keep-alive **pendant** la requÃªte HTTP
- âŒ Process dÃ©truit **aprÃ¨s** la rÃ©ponse
- âŒ Pas de rÃ©utilisation entre requÃªtes
- âš¡ Gain: spawn overhead rÃ©duit **dans** la requÃªte (1.2s vs 2.5s)

**Exemple**:
```
Request 1: Spawn (0.5s) â†’ Execute (1.2s) â†’ Destroy
Request 2: Spawn (0.5s) â†’ Execute (1.2s) â†’ Destroy â† Nouveau process!
Request 3: Spawn (0.5s) â†’ Execute (1.2s) â†’ Destroy â† Nouveau process!
```

### Architecture Cible (v32) - Multi-Request Keep-Alive

```
Client Request 1 â†’ FastAPI
                      â†“
              Get Process from Pool
                      â†“
              (Create if not exists)
                      â†“
              Send Message
                      â†“
              Stream Response
                      â†“
              Return Process to Pool âœ…
                      â†“
              Return to Client

Client Request 2 â†’ FastAPI
                      â†“
              Get SAME Process âœ…
                      â†“
              Send Message
                      â†“
              Stream Response
                      â†“
              Return Process to Pool âœ…
```

**CaractÃ©ristiques**:
- âœ… Process keep-alive **entre** requÃªtes HTTP
- âœ… Process rÃ©utilisÃ© pour le mÃªme user
- âœ… Context maintenu automatiquement
- âš¡ Gain: spawn overhead Ã©liminÃ© **entre** requÃªtes (0.8s vs 1.7s aprÃ¨s request 1)

**Exemple**:
```
Request 1: Spawn (0.5s) â†’ Execute (1.2s) â†’ Pool âœ…
Request 2: Get from Pool (0.0s) â†’ Execute (0.8s) â†’ Pool âœ… â† MÃªme process!
Request 3: Get from Pool (0.0s) â†’ Execute (0.8s) â†’ Pool âœ… â† MÃªme process!
```

**Performance Gain**:
```
Request 1: 1.7s (avec spawn)
Request 2: 0.8s (sans spawn) â† 2.1Ã— plus rapide
Request 3: 0.8s (sans spawn) â† 2.1Ã— plus rapide
```

---

## ğŸ—ï¸ Composants du Process Pool

### 1. Structure de DonnÃ©es: `ProcessInfo`

**RÃ´le**: Stocker les mÃ©tadonnÃ©es d'un process actif

```python
@dataclass
class ProcessInfo:
    process: subprocess.Popen        # Le process Claude CLI
    workspace_path: Path             # Workspace de l'utilisateur
    stdin_writer: threading.Thread   # Thread d'Ã©criture stdin
    stdout_reader: threading.Thread  # Thread de lecture stdout
    event_queue: queue.Queue         # File d'Ã©vÃ©nements
    last_used: float                 # Timestamp derniÃ¨re utilisation
    user_id: str                     # Identifiant user (hash token)
    created_at: float                # Timestamp crÃ©ation
```

**Pourquoi ces champs?**
- `process`: Pour envoyer stdin et lire stdout
- `workspace_path`: Pour cleanup lors destruction
- `stdin_writer`/`stdout_reader`: Threads non-bloquants (I/O bidirectionnel)
- `event_queue`: Communication thread-safe entre threads
- `last_used`: Pour cleanup automatique (idle timeout)
- `user_id`: Isolation par utilisateur
- `created_at`: Debugging et monitoring

### 2. Pool Dictionary: `_process_pool`

**RÃ´le**: Mapping user_id â†’ ProcessInfo

```python
_process_pool: Dict[str, ProcessInfo] = {}
_pool_lock = threading.Lock()  # Thread-safety
```

**Exemple**:
```python
{
    "abc123def456": ProcessInfo(
        process=<Popen pid=12345>,
        workspace_path="/workspaces/abc123def456",
        last_used=1699876543.123,
        user_id="abc123def456",
        ...
    ),
    "fed456cba987": ProcessInfo(
        process=<Popen pid=67890>,
        workspace_path="/workspaces/fed456cba987",
        last_used=1699876550.456,
        user_id="fed456cba987",
        ...
    )
}
```

**Thread-Safety**:
```python
with _pool_lock:
    if user_id in _process_pool:
        process_info = _process_pool[user_id]
```

### 3. Cleanup Thread: `_cleanup_loop()`

**RÃ´le**: DÃ©truire les process idle (inactifs depuis >5min)

```python
def _cleanup_loop():
    """Background thread pour cleanup automatique."""
    while True:
        time.sleep(60)  # Check toutes les 60 secondes

        with _pool_lock:
            now = time.time()
            to_remove = []

            for user_id, info in _process_pool.items():
                idle_time = now - info.last_used

                if idle_time > 300:  # 5 minutes
                    logger.info(f"Cleanup idle process: {user_id} (idle: {idle_time:.1f}s)")
                    to_remove.append(user_id)

            for user_id in to_remove:
                _cleanup_process(user_id)
```

**Pourquoi 5 minutes?**
- âœ… Assez long pour conversations courtes (2-3 Ã©changes rapides)
- âœ… Assez court pour Ã©viter accumulation mÃ©moire
- âš™ï¸ Configurable via variable d'environnement

---

## ğŸ”„ Flux de RequÃªte DÃ©taillÃ©

### Scenario: 3 requÃªtes du mÃªme user avec 2 minutes entre chaque

#### Request 1: CrÃ©ation du process

```
1. Client envoie Request 1
   â†“
2. FastAPI: POST /v1/messages/pooled
   â†“
3. get_or_create_process(user_id)
   â†“
4. Check pool: user_id NOT in _process_pool
   â†“
5. Spawn new Claude CLI process
   |  - Workspace: /workspaces/abc123def456
   |  - Threads: stdin_writer + stdout_reader
   |  - Queue: event_queue
   â†“
6. Add to pool: _process_pool[user_id] = ProcessInfo(...)
   â†“
7. Send message via stdin
   â†“
8. Read events from queue (streaming)
   â†“
9. Update last_used timestamp
   â†“
10. Return response to client
    (Process reste dans pool âœ…)
```

**Timing**: 1.7s (spawn 0.5s + execute 1.2s)

#### Request 2: RÃ©utilisation (2 minutes plus tard)

```
1. Client envoie Request 2 (same user)
   â†“
2. FastAPI: POST /v1/messages/pooled
   â†“
3. get_or_create_process(user_id)
   â†“
4. Check pool: user_id IN _process_pool âœ…
   â†“
5. Get existing ProcessInfo
   |  - Process already running
   |  - Threads already active
   |  - Context maintained
   â†“
6. Send message via SAME stdin
   â†“
7. Read events from SAME queue
   â†“
8. Update last_used timestamp
   â†“
9. Return response to client
    (Process reste dans pool âœ…)
```

**Timing**: 0.8s (no spawn, direct execute)
**Gain**: 2.1Ã— plus rapide que Request 1

#### Request 3: RÃ©utilisation (2 minutes plus tard)

```
Same as Request 2
```

**Timing**: 0.8s
**Gain**: 2.1Ã— plus rapide

#### After 5 minutes idle: Cleanup automatique

```
1. Cleanup thread checks pool
   â†“
2. Find user_id with idle_time > 300s
   â†“
3. _cleanup_process(user_id)
   |  - Stop threads
   |  - Terminate process
   |  - Remove from pool
   |  - Delete workspace
   â†“
4. Pool now empty
```

---

## ğŸ” SÃ©curitÃ© et Isolation

### Isolation par User

**Question**: Comment garantir que User A ne peut pas accÃ©der aux donnÃ©es de User B?

**RÃ©ponse**: Chaque user a son propre process + workspace

```python
# User A
_process_pool["abc123def456"] = ProcessInfo(
    workspace_path="/workspaces/abc123def456",  # Permissions 0o700
    ...
)

# User B
_process_pool["fed456cba987"] = ProcessInfo(
    workspace_path="/workspaces/fed456cba987",  # Permissions 0o700
    ...
)
```

**Garanties**:
- âœ… Process sÃ©parÃ©s (isolation PID)
- âœ… Workspaces sÃ©parÃ©s (isolation filesystem)
- âœ… Credentials sÃ©parÃ©s (temporaire, 0o600)
- âœ… Aucun partage mÃ©moire/CPU

### Token Hijacking Prevention

**ProblÃ¨me**: Que se passe-t-il si un attaquant devine un `user_id`?

**RÃ©ponse**: Le `user_id` est dÃ©rivÃ© du token OAuth (SHA256)

```python
user_id = hashlib.sha256(access_token.encode()).hexdigest()[:16]
```

**ScÃ©nario d'attaque**:
1. Attacker devine `user_id` = "abc123def456"
2. Attacker envoie requÃªte avec un faux token
3. Wrapper calcule `user_id` = SHA256(fake_token)[:16] = "xyz789uvw012"
4. Wrapper cherche dans pool: `_process_pool["xyz789uvw012"]` â†’ **NOT FOUND**
5. Wrapper spawn NOUVEAU process pour "xyz789uvw012"
6. Attacker n'accÃ¨de JAMAIS au process de la victime

**Garantie**: Impossible d'accÃ©der au process d'un autre user sans connaÃ®tre son token OAuth exact.

---

## âš¡ Performance Comparison

### Latency (Single User, 10 Requests)

| Architecture | Request 1 | Request 2-10 | Total |
|--------------|-----------|--------------|-------|
| v31 (single-request) | 1.7s | 1.7s Ã— 9 = 15.3s | **17.0s** |
| v32 (process pool) | 1.7s | 0.8s Ã— 9 = 7.2s | **8.9s** |
| **Gain** | - | - | **1.9Ã— faster** |

### Memory (100 Concurrent Users)

| Architecture | Memory per User | Total Memory |
|--------------|-----------------|--------------|
| v31 (single-request) | Process destroyed after request | **~200 MB** (only during requests) |
| v32 (process pool) | Process alive 5min idle | **~500 MB** (if all idle) |

**Trade-off**: Latency vs Memory

---

## ğŸš§ Cas d'Usage

### âœ… Process Pool RecommandÃ©

1. **Chat applications** (conversations >3 Ã©changes rapides)
   - Exemple: User envoie 5 messages en 2 minutes
   - Gain: 0.8s Ã— 4 requests Ã©conomisÃ©es = **3.6s saved**

2. **Auto-retry workflows** (retry aprÃ¨s erreur)
   - Exemple: Request Ã©choue â†’ Client retry immÃ©diatement
   - Gain: Pas de re-spawn

3. **High-frequency users** (>10 requests/hour)
   - Gain: Latency constante basse (0.8s)

### âŒ Process Pool PAS RecommandÃ©

1. **Batch processing** (1 requÃªte isolÃ©e)
   - Pas de gain (spawn unavoidable)
   - SurcoÃ»t mÃ©moire inutile

2. **Long idle times** (>10min entre requÃªtes)
   - Process dÃ©truit avant 2Ã¨me requÃªte
   - Pas de gain

3. **Memory-constrained environments**
   - Pool consomme mÃ©moire mÃªme idle
   - PrÃ©fÃ©rer v31 (stateless)

---

## ğŸ” Monitoring et Debugging

### Endpoint Stats: `GET /v1/pool/stats`

**Response Example**:
```json
{
  "pool_size": 23,
  "active_users": [
    {
      "user_id": "abc123def456",
      "idle_time": 45.2,
      "created_at": "2025-11-07T10:23:15Z",
      "last_used": "2025-11-07T10:24:00Z",
      "uptime": 102.5
    },
    {
      "user_id": "fed456cba987",
      "idle_time": 120.8,
      "created_at": "2025-11-07T10:20:10Z",
      "last_used": "2025-11-07T10:22:00Z",
      "uptime": 350.3
    }
  ],
  "cleanup_stats": {
    "last_cleanup": "2025-11-07T10:23:00Z",
    "total_cleaned": 5,
    "avg_lifetime": 245.6
  }
}
```

### Logs

```python
logger.info(f"Pool hit: user={user_id}, idle={idle_time:.1f}s")
logger.info(f"Pool miss: user={user_id}, spawning new process")
logger.info(f"Cleanup: user={user_id}, idle={idle_time:.1f}s, reason=timeout")
```

---

## ğŸ“‹ Checklist ImplÃ©mentation

### Phase 1: Core Logic (2h)
- [ ] CrÃ©er `ProcessInfo` dataclass
- [ ] CrÃ©er `_process_pool` dict + lock
- [ ] ImplÃ©menter `_get_or_create_process()`
- [ ] ImplÃ©menter `create_message_pooled()`
- [ ] Tester avec 2 requÃªtes same user

### Phase 2: Cleanup (1h)
- [ ] ImplÃ©menter `_cleanup_loop()` thread
- [ ] ImplÃ©menter `_cleanup_process()`
- [ ] Tester cleanup aprÃ¨s 5min idle
- [ ] VÃ©rifier workspace deletion

### Phase 3: FastAPI (1h)
- [ ] CrÃ©er endpoint `/v1/messages/pooled`
- [ ] CrÃ©er endpoint `/v1/pool/stats`
- [ ] Tester avec curl
- [ ] VÃ©rifier streaming SSE

### Phase 4: Testing (1h)
- [ ] Test: 10 requests same user (vÃ©rifier latency)
- [ ] Test: 2 users simultanÃ©s (vÃ©rifier isolation)
- [ ] Test: Idle cleanup (vÃ©rifier timeout)
- [ ] Test: Memory usage (100 users)

**Total**: 5 heures

---

## ğŸ¯ DÃ©cision: v31 vs v32

### Garder v31 si:
- âŒ Users font 1-2 requÃªtes/session
- âŒ Long idle times (>10min)
- âŒ Memory-constrained (Cloud Run min instances)

### ImplÃ©menter v32 si:
- âœ… Users font 3+ requÃªtes rapides
- âœ… Chat application (conversations)
- âœ… Latency critique (<1s)
- âœ… High-frequency users (>10 req/hour)

---

## ğŸš€ Next Steps

1. **DÃ©cision**: v31 suffisant ou v32 nÃ©cessaire?
2. **Si v32**: ImplÃ©menter selon checklist (5h)
3. **Testing**: Comparer perfs v31 vs v32
4. **Production**: Deploy v32 avec A/B testing

---

**Status**: ğŸ“š Ã‰tude complÃ¨te - PrÃªt pour dÃ©cision
